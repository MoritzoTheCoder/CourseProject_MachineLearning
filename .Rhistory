result <- optimize(f = min.fun, par = mu,  data=data, lower = min(par),
upper = max(par), maximum = FALSE,
tol = .Machine$double.eps^0.25)
result <- optimize(f = min.fun, interval = c(-1.54, 0.95),  data=data, lower = min(interval),
upper = max(interval), maximum = FALSE,
tol = .Machine$double.eps^0.25)
result <- optimize(f = min.fun,  data=data, lower = -1.54,
upper = 0.95, maximum = FALSE,
tol = .Machine$double.eps^0.25)
result
result <- optimize(f = min.fun,  data=data, lower = -1.54,
upper = 0.95, maximum = FALSE,
tol = 0.001)
result
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
result <- lm(y ~ x -1)
result
data(mtcars)
mtcars
class(mtcars)
result <- lm(mpg ~ wt, data=mtcars)
result
result <- lm(y ~ x )
result
result <- lm(y ~ x + 0)
result
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
x.n <- (x - mean(x)) / sd(x)
x.n
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
result <- lm(y ~ x)
result
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
result <- lm(y ~ x)
result
str(result)
result$effects
result$qr
result$coef
summary(result)
summary(result)
?matcars
??matcars
result <- lm(mpg ~ wt, data=mtcars)
summary(result)
confint(result, "wt", level=0.95)
result$coef[1] + 3 * confint(result, "wt", level=0.95)[2]
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
data <- data.frame(x=x,w=w)
min.fun <- function(data, par) {
with(data, sum(w*(x-par)^2))
}
result <- optimize(f = min.fun,  data=data, lower = -1.54,
upper = 0.95, maximum = FALSE,
tol = 0.001)
result
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
result <- lm(y ~ x + 0)
result
data(mtcars)
result <- lm(mpg ~ wt, data=mtcars)
result
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
x.n <- (x - mean(x)) / sd(x)
x.n
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
result <- lm(y ~ x)
result
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
result <- lm(y ~ x)
result
summary(result)
fit <- lm(mpg ~ I(wt - mean(wt)), data = mtcars)
confint(fit)
fit <- lm(mpg ~ wt, data = mtcars)
predict(fit, newdata = data.frame(wt = 3), interval = "prediction")
fit <- lm(mpg ~ I(wt * 0.5), data = mtcars)
confint(fit)[2, ]
fit1 <- lm(mpg ~ wt, data = mtcars)
fit2 <- lm(mpg ~ 1, data = mtcars)
1 - summary(fit1)$r.squared
summary(fit2)$r.squared
summary(fit2)
summary(fit1)
1 - summary(fit1)$r.squared
data(mtcars)
mtcars <- as.data.frame(mtcars)
fit <- lm(mpg ~ wt, mtcars)
summary(fit)
resid(fit)
res1.mpg <- resid(fit)
median(res1.fit)
median(res1.mpg)
fit <- lm(am ~ wt, mtcars)
summary(fit)
res.am <- resid(fit)
fit.res <- lm(res.mpg ~ res.am, mtcars)
fit.res <- lm(res1.mpg ~ res.am, mtcars)
summary(fit.res)
fit <- lm(wt ~ am, mtcars)
summary(fit)
fit <- lm(mpg ~ am, mtcars)
summary(fit)
res1.mpg <- resid(fit)
fit <- lm(wt ~ am, mtcars)
summary(fit)
res.wt <- resid(fit)
fit.res <- lm(res1.mpg ~ res.wt, mtcars)
summary(fit.res)
fit <- lm(mpg ~ wt, mtcars)
res2.mpg <- resid(fit)
fit <- lm(am ~ wt, mtcars)
res.am <- resid(fit)
fit.resB <- lm(res2.mpg ~ res.am, mtcars)
summary(fit.res)
summary(fit.resB)
fit <- lm(mpg ~ cyl + disp, mtcars)
summary(fit)
fit <- lm(mpg ~ factor(cyl) + disp, mtcars)
summary(fit)
res1.mpg <- resid(fit)
res1.mpg
hist(res1.mpg)
summary(res1.mpg)
fit <- lm(mpg ~ disp, mtcars)
summary(fit)
fit <- lm(mpg ~ hp, mtcars)
summary(fit)
fit <- lm(mpg ~ hp + disp, mtcars)
summary(fit)
fit <- lm(mpg ~ hp + cyl, mtcars)
summary(fit)
fit <- lm(mpg ~ am + wt, mtcars)
summary(fit)
summary(fit)¢coef
summary(fit)$coef
summary(fit)$coef
fit <- lm(mpg ~ am, mtcars)
res1.mpg <- resid(fit)
fit <- lm(wt ~ am, mtcars)
res.wt <- resid(fit)
fit.res <- lm(res1.mpg ~ res.wt, mtcars)
summary(fit.res)$coef
fit <- lm(mpg ~ factor(cyl) + wt, mtcars)
summary(fit)
fit <- lm(mpg ~ factor(cyl) + wt, mtcars)
summary(fit)
cyl.2 <- relevel(mtcars$cyl, 4)
cyl.2 <- relevel(factor(mtcars$cyl), 4)
cyl.2 <- relevel(factor(mtcars$cyl), 2)
fit2 <- lm(mpg ~ factor(cyl), mtcars)
summary(fit2)
fit3 <- lm(mpg ~ factor(cyl) + wt + factor(cyl)*wt, mtcars)
summary(fit3)
?stats::logLik
logLik(fit1)
logLik(fit)
logLik(fit3)
require(lmtest)
install.packages("lmtest")
library(lmtest)
lrt <- lrtest(fit, fit3)
lrt
lrt <- lrtest(fit3, fit)
lrt
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
summary(lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars))
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit5 <- lm(y ~x)
summary(fit5)
?lm
influence.measures(fit5)
hatvalues(fit5)
round(dfbetas(fit5), 3)
hat(fit5)
hat(influence.measures(fit5))
hat(influence.measures(fit5)$hat)
plot(hat(influence.measures(fit5)$hat))
fit5 <- lm(y ~x)
hat(influence.measures(fit5)$hat)
hat(influence.measures(fit5)$x)
lm.influence(fit5)$hat)
lm.influence(fit5)$hat
hat(lm.influence(fit5)$hat)
plot(hat(lm.influence(fit5)$hat))
influence.measures(fit5)
library(MASS)
data(shuttle)
Shuttle <- as.data.frame(shuttle)
?shuttle
glm1 <- glm(auto ~ wind, data=Shuttle, family="binary")
glm1 <- glm(auto ~ wind, data=Shuttle, family="bernouli")
glm1 <- glm(auto ~ wind, data=Shuttle, family="bernoulli")
glm1 <- glm(auto ~ wind, data=Shuttle, family="binomial")
glm1 <- glm(use ~ wind, data=Shuttle, family="binomial")
summary(glm1)
summary(glm1)$coef[2]
summary(glm1)$coef[2]
exp(summary(glm1)$coef[2])
glm2 <- glm(use ~ wind + magn, data=Shuttle, family="binomial")
summary(glm2)
summary(glm2)$coef[2]
exp(summary(glm2)$coef[2])
glm3 <- glm(I(1-use) ~ wind, data=Shuttle, family="binomial")
hist(Shuttle$auto)
table(Shuttle$auto)
summary(Shuttle$use)
class(Shuttle$use)
Shuttle¢use <- relevel(Shuttle$use, "nonauto")
Shuttle$use <- relevel(Shuttle$use, "nonauto")
Shuttle$use <- relevel(Shuttle$use, "noauto")
glm3 <- glm(use ~ wind, data=Shuttle, family="binomial")
summary(glm3)
table(Shuttle$auto)
summary(Shuttle$use)
glm3 <- glm(I(ordered(use, levels=c("noauto", "auto"))) ~ wind, data=Shuttle, family="binomial")
summary(glm3)
data(InsectSprays)
sprays <- as.data.frame(InsectSprays)
?InsectSprays
glm4 <- glm(count ~ spray, data=sprays, family="poisson")
summary(glm4)
glm4 <- glm(count ~ spray -1, data=sprays, family="poisson")
summary(glm4)
exp(coef(glm4))
library(pgmm)
install.packages("pgm")
library(pgmm)
install.packages("pgmm")
library(pgmm)
data(olive)
View(olive)
olive = olive[,-1]
View(olive)
colMeans(olive)
t(colMeans(olive))
?t
model3 <- train(Area ~ ., data=olive, method="rpart")
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
model3 <- train(Area ~ ., data=olive, method="rpart")
is.na(olive)
table(is.na(olive))
model3 <- train(Area ~ ., data=olive, method="rpart")
model3$finalModel
newdata = as.data.frame(t(colMeans(olive)))
View(newdata)
predict.colMeans <- predict(model3, newdata)
##################################################################################################################
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
View(SAheart)
model4 <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA, method="glm", family="binomial")
str(SAheart)
SAheart$chd <- factor(SAheart$chd)
str(SAheart)
View(SAheart)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
model4 <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA, method="glm", family="binomial")
model4$values
model4
prediction.intest <-predict(model4, testSA, type='response')
prediction.intest <-predict(model4, testSA, type='raw')
prediction.intest
prediction.fortrain <-predict(model4, trainSA, type='raw')
prediction.fortrain
View(trainSA)
length(prediction.fortrain)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, prediction.fortrain)
missClass(as.numeric(trainSA$chd), as.numeric(prediction.fortrain))
missClass(as.numeric(testSA$chd), as.numeric(prediction.fortest))
prediction.fortest <-predict(model4, testSA, type='raw')
missClass(as.numeric(testSA$chd), as.numeric(prediction.fortest))
model4 <- train(chd~age+alcohol+obesity+tobacco+typea+ldl, data=trainSA, method="glm", family=binomial(link='logit'))
summary(model4)
model4
str(trainSA)
model4 <- train(chd~age+alcohol+obesity+tobacco+typea+ldl, data=trainSA[c(2,3,6,7,8,9,10)], method="glm", family=binomial(link='logit'))
model4
prediction.fortrain <-predict(model4, trainSA, type='raw')
prediction.fortest <-predict(model4, testSA, type='raw')
missClass(as.numeric(testSA$chd), as.numeric(prediction.fortest))
missClass(as.numeric(trainSA$chd), as.numeric(prediction.fortrain))
prediction.fortrain <-predict(model4, trainSA, type='prob')
prediction.fortrain <-predict(model4, trainSA[c(2,3,6,7,8,9,10)], type='prob')
prediction.fortrain <-predict(model4, trainSA[c(2,3,6,7,8,9)], type='prob')
str(trainSA)
prediction.fortrain <-predict(model4, trainSA[c(2,3,6,7,8,9)], type='probs')
set.seed(13234)
model4 <- train(chd~age+alcohol+obesity+tobacco+typea+ldl, data=trainSA[c(2,3,6,7,8,9,10)], method="glm", family=binomial(link='logit'))
summary(model4)
prediction.fortrain <-predict(model4, trainSA[c(2,3,6,7,8,9)], type='prob')
rm(SAheart)
rm(SAtraining, SAtesting)
rm(SAtrain, SAtest)
rm(trainSA, testSA)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
model4 <- train(chd~age+alcohol+obesity+tobacco+typea+ldl, data=trainSA[c(2,3,6,7,8,9,10)], method="glm", family=binomial(link='logit'))
model4
prediction.fortrain <-predict(model4, trainSA[c(2,3,6,7,8,9)], type='prob')
prediction.fortrain <-predict(model4, trainSA[c(2,3,6,7,8,9,10)], type='prob')
prediction.fortest <-predict(model4, testSA[c(2,3,6,7,8,9,10)], type='prob')
set.seed(13234)
model4 <- glm(chd~age+alcohol+obesity+tobacco+typea+ldl, data=trainSA, family=binomial(link='logit'))
summary(model4)
prediction.fortrain <-predict(model4, trainSA[c(2,3,6,7,8,9,10)], type='prob')
prediction.fortrain <-predict(model4, trainSA[c(2,3,6,7,8,9,10)], type='response')
prediction.fortrain
prediction.fortest <-predict(model4, testSA[c(2,3,6,7,8,9,10)], type='response')
missClass(testSA$chd, prediction.fortest)
missClass(trainSA$chd, prediction.fortrain)
prediction.fortrain <-predict(model4, trainSA, type='response')
prediction.fortrain
prediction.fortest <-predict(model4, testSA, type='response')
missClass(testSA$chd, prediction.fortest)
missClass(trainSA$chd, prediction.fortrain)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train
vowel.test
View(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
View(vowel.train)
model5 <- train(y ~ ., data=train, method="rf", prox=T)
model5 <- train(y ~ ., data=vowel.train, method="rf", prox=T)
model5 <- train(y ~ ., data=vowel.train, method="rf", prox=T)
model5
varImp(model5$finalModel)
varImp(model5)
varImp(model5$finalModel, scale=T)
varImp(model5, scale=T)
varImp(rfmod)
set.seed(33833)
model5 <- train(y ~ ., data=vowel.train, method="rf", prox=T)
model5
varImp(model5$finalModel, scale=T)
setwd("~/Desktop/Coursera_DataScience/8_PracticalMachineLearning")
rm()
ls()
rm(list = ls())
setwd("~/Desktop/Coursera_DataScience/8_PracticalMachineLearning/CourseProject_MachineLearning")
training <- read.csv("pml-testing.csv")
View(training)
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
str(training)
apply(training, 2, function(x) length(which(!is.na(x))))
missings <- apply(training, 2, function(x) length(which(!is.na(x))))
str(missings)
dim(missings)
class(missings)
missings <- sapply(training, function(x) length(which(!is.na(x))))
class(missings)
dim(missings)
missings <- sapply(training, function(x) length(which(is.na(x))))
colSums(is.na(training))
missings <- colSums(is.na(training))
class(missings)
str(missings)
missings <- as.data.frame(colSums(is.na(training)))
View(missings)
unique(missings)
unique(colSums(is.na(training)))
table(colSums(is.na(training)))
index <- which(colSums(is.na(training)) == 0)
training.BACKUP <- training
index
is.vector(index)
training <- training[,-index]
View(training)
training <- training.BACKUP
training <- training[,-c(index)]
training <- training.BACKUP
training <- training[,index]
View(training)
table(colSums(is.na(training))) # How many variables are usable with regard to missing values?
unique(colSums(is.na(training)))
View(training.BACKUP)
is.na(training.BACKUP$min_yaw_dumbbell)
table(is.na(training.BACKUP$min_yaw_dumbbell))
index <- which(colSums(is.na(training)) == 0)
index
training.BACKUP[,"classe"]
str(training.BACKUP)
tail(str(training.BACKUP), 50)
training.BACKUP[,"classe"] == training[,"classe"]
unique(training$classe)
unique(training.BACKUP$classe)
table(training.BACKUP$classe)
table(training$classe)
tmp <- training.BACKUP[,130:160]
View(tmp)
training <- read.csv("pml-training.csv", na.strings=c("", "NA"), sep=",")
colSums(is.na(training))
unique(colSums(is.na(training)))
table(colSums(is.na(training))) # How many variables are usable with regard to missing values?
View(training)
tmp <- training.BACKUP[,130:160]
View(tmp)
index <- which(colSums(is.na(training)) == 0)
training <- training[,index]
View(training)
unique(training$classe)
table(training$classe)
class(training$classe)
library(caret)
str(training)
model1 <- train(classe ~ ., data=training, method="rf", prox=T)
index2 <- index
index2 <- index2[-7]
index2 <- index
index2 <- index2[-c(1,2,3,4,5,6,7)]
rm(missings, testing, tmp, training, index, index2)
training <- read.csv("pml-training.csv", na.strings=c("", "NA", "#DIV/0!"), sep=",")
testing <- read.csv("pml-testing.csv", na.strings=c("", "NA", "#DIV/0!"), sep=",")
table(training$classe)
class(training$classe)
colSums(is.na(training))
unique(colSums(is.na(training)))
table(colSums(is.na(training))) # How many variables are usable with regard to missing values?
which(colSums(is.na(training)) == 0)
index <- which(colSums(is.na(training)) == 0)
index <- index[-c(1,2,3,4,5,6,7)]
training.BACKUP2 <- training
training <- training[,index]
View(training)
index.subsamples <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
training.sub <- trainingset[index.subsamples, ]
training.sub <- training[index.subsamples, ]
testing.sub <- training[-index.subsamples, ]
model.rpart <- train(classe ~ ., data=training.sub, method="rpart")
model.rpart
summary(model.rpart)
predictionTree.rpart <- predict(model.rpart, newdata=testing.sub, type = "class")
predictionTree.rpart <- predict(model.rpart, newdata=testing.sub, type = "classe")
predictionTree.rpart <- predict(model.rpart, newdata=testing.sub, type = "raw")
rpart.plot(model.rpart, main="Classification Tree", extra=102, under=TRUE, faclen=0)
library(rpart)
rpart.plot(model.rpart, main="Classification Tree", extra=102, under=TRUE, faclen=0)
plot(model.rpart, main="Classification Tree", extra=102, under=TRUE, faclen=0)
plot(model.rpart$finalModel, main="Classification Tree", uniform=T)
text(model.rpart$finalModel, use.n=T, all=T, cex=0.6)
library(rpart.plot)
install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(model.rpart, main="Classification Tree", extra=102, under=TRUE, faclen=0)
library(rpart)
library(randomForest)
table(names(training) == names(testing))
table(names(training) == names(testing[,index]))
View(testing)
tmp <- testing[,130:160]
View(tmp)
length(names(training))
length(names(testing[,index]))
rfNews
trControl <- trainControl(method = "cv", number = 4, allowParallel = TRUE)
rm(trControl)
setControl <- trainControl(method = "cv", number = 4, allowParallel = TRUE)
model.rf <- train(classe ~ ., data=training.sub, method="rf", trControl = setControl )
save.image("~/Desktop/Coursera_DataScience/8_PracticalMachineLearning/CourseProject_MachineLearning/CourseProject.RData")
model.rf$results
model.rf$finalModel
Prediction.test <- predict(model.rf$final, newdata=testing.sub)
confusionMatrix(Prediction.test, testing.sub$classe)
cM.rf <- confusionMatrix(Prediction.test, testing.sub$classe)
cM.rf$overall[1]
cM.rf$overall[[1]]
testing.BACKUP <- testing
testing <- testing[,index]
View(testing)
testing <- testing[,-53]
View(testing)
Prediction.testing <- predict(model.rf, testing)
Prediction.testing <- as.character(Prediction.testing)
pml_write_files = function(x) {
n = length(x)
for (i in 1:n) {
filename = paste0("problem_id_", i, ".txt")
write.table(x[i], file = filename, quote = FALSE, row.names = FALSE,
col.names = FALSE)
}
}
pml_write_files(Prediction.testing)
Prediction.testing
